import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import cv2
import os
import urllib.request
from PIL import Image, ImageDraw

# --- Û±. ØªØ¹Ø±ÛŒÙ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ø¯Ù„ UNet ---
class UNet(nn.Module):
    def __init__(self, n_channels=1, n_classes=29):
        super(UNet, self).__init__()
        self.inc = self.double_conv(n_channels, 64)
        self.down1 = self.down(64, 128)
        self.down2 = self.down(128, 256)
        self.down3 = self.down(256, 512)
        self.up1 = self.up(512, 256)
        self.up2 = self.up(256, 128)
        self.up3 = self.up(128, 64)
        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)

    def double_conv(self, in_c, out_c):
        return nn.Sequential(
            nn.Conv2d(in_c, out_c, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_c, out_c, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_c),
            nn.ReLU(inplace=True)
        )

    def down(self, in_c, out_c):
        return nn.Sequential(nn.MaxPool2d(2), self.double_conv(in_c, out_c))

    def up(self, in_c, out_c):
        return nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2)

    def forward(self, x):
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x = self.up1(x4)
        x = self.up2(x)
        x = self.up3(x)
        return self.outc(x)

# --- Û². Ù…Ø¯ÛŒØ±ÛŒØª Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ (Ensemble) ---
@st.cache_resource
def load_all_models():
    device = torch.device('cpu')
    os.makedirs('models', exist_ok=True)
    
    # Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ Ù…Ø³ØªÙ‚ÛŒÙ… Ù…Ø¯Ù„â€ŒÙ‡Ø§ (Ø¨Ø§ÛŒØ¯ Ù„ÛŒÙ†Ú© Ù…Ø³ØªÙ‚ÛŒÙ… Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯)
    # Ø§Ú¯Ø± Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ø¯Ø± Ø¯Ø±Ø§ÛŒÙˆ Ù‡Ø³ØªÙ†Ø¯ØŒ Ø¨Ø§ÛŒØ¯ Ù„ÛŒÙ†Ú© Direct Download Ø¨Ø³Ø§Ø²ÛŒØ¯
    model_urls = {
        'general': 'Ù„ÛŒÙ†Ú©_Ù…Ø³ØªÙ‚ÛŒÙ…_Ù…Ø¯Ù„_Ø¹Ù…ÙˆÙ…ÛŒ',
        'specialist': 'Ù„ÛŒÙ†Ú©_Ù…Ø³ØªÙ‚ÛŒÙ…_Ù…Ø¯Ù„_Ø§Ø³Ù¾Ø´ÛŒØ§Ù„ÛŒØ³Øª',
        'tmj': 'Ù„ÛŒÙ†Ú©_Ù…Ø³ØªÙ‚ÛŒÙ…_Ù…Ø¯Ù„_tmj'
    }
    
    checkpoints = {
        'general': 'models/checkpoint_unet_clinical.pth',
        'specialist': 'models/specialist_pure_model.pth',
        'tmj': 'models/tmj_specialist_model.pth'
    }
    
    models = {}
    for name, path in checkpoints.items():
        # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ Ø¯Ø± Ø³Ø±ÙˆØ± Ø§Ø³ØªØ±ÛŒÙ…â€ŒÙ„ÛŒØª Ù†Ø¨ÙˆØ¯ØŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø´ÙˆØ¯
        if not os.path.exists(path):
            with st.spinner(f'Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø¯Ù„ {name}... (Ø§ÛŒÙ† Ú©Ø§Ø± ÙÙ‚Ø· ÛŒÚ©Ø¨Ø§Ø± Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯)'):
                # urllib.request.urlretrieve(model_urls[name], path) # ØºÛŒØ±ÙØ¹Ø§Ù„ ØªØ§ Ø²Ù…Ø§Ù† Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†ÛŒ Ù„ÛŒÙ†Ú©
                pass 
        
        model = UNet(n_channels=1, n_classes=29)
        if os.path.exists(path):
            model.load_state_dict(torch.load(path, map_location=device))
        model.eval()
        models[name] = model
    return models, device

# --- Û³. ØªÙˆØ§Ø¨Ø¹ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ Ø¢Ù†Ø§Ù„ÛŒØ² Steiner Ùˆ McNamara ---
def get_landmarks(heatmaps):
    landmark_names = [
        'Sella', 'Nasion', 'A-point', 'B-point', 'Pogonion', 'Menton', 'Gnathion', 
        'Gonion', 'Orbitale', 'Porion', 'Condylion', 'Articulare', 'ANS', 'PNS',
        'Upper Incisor Tip', 'Lower Incisor Tip', 'Soft Tissue Nasion', 'Tip of Nose', 
        'Soft Tissue Menton', 'TMJ_Point', 'Ricketts_Point' # Ùˆ Ù…Ø§Ø¨Ù‚ÛŒ ØªØ§ Û²Û¹ Ù†Ù‚Ø·Ù‡
    ]
    landmarks = {}
    for i in range(min(len(landmark_names), heatmaps.shape[1])):
        heatmap = heatmaps[0, i].cpu().numpy()
        _, _, _, max_loc = cv2.minMaxLoc(heatmap)
        landmarks[landmark_names[i]] = max_loc
    return landmarks

def calculate_ortho_analysis(pts, pixel_size):
    def get_angle(p1, p2, p3):
        v1, v2 = np.array(p1) - np.array(p2), np.array(p3) - np.array(p2)
        dot = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))
        return np.degrees(np.arccos(np.clip(dot, -1.0, 1.0)))

    res = {}
    try:
        if all(k in pts for k in ['Sella', 'Nasion', 'A-point']):
            res['SNA'] = get_angle(pts['Sella'], pts['Nasion'], pts['A-point'])
        if all(k in pts for k in ['Sella', 'Nasion', 'B-point']):
            res['SNB'] = get_angle(pts['Sella'], pts['Nasion'], pts['B-point'])
        if 'SNA' in res and 'SNB' in res:
            res['ANB'] = res['SNA'] - res['SNB']
        if all(k in pts for k in ['Condylion', 'A-point']):
            res['McNamara_Length'] = np.linalg.norm(np.array(pts['Condylion']) - np.array(pts['A-point'])) * pixel_size
    except: pass
    return res

# --- Û´. Ø¨Ø¯Ù†Ù‡ Ø§ØµÙ„ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Streamlit ---
st.set_page_config(page_title="CephRad AI", layout="centered")
st.title("ğŸ¦· CephRad: Ø¢Ù†Ø§Ù„ÛŒØ² Ù‡ÙˆØ´Ù…Ù†Ø¯ Ø±Ø§Ø¯ÛŒÙˆÚ¯Ø±Ø§ÙÛŒ")

uploaded_file = st.file_uploader("ØªØµÙˆÛŒØ± Ø³ÙØ§Ù„ÙˆÙ…ØªØ±ÛŒ Ø±Ø§ Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯", type=['png', 'jpg', 'jpeg'])

if uploaded_file:
    img = Image.open(uploaded_file).convert('RGB')
    st.image(img, caption="ØªØµÙˆÛŒØ± ÙˆØ±ÙˆØ¯ÛŒ", use_column_width=True)

    if st.button("ğŸš€ Ø§Ø¬Ø±Ø§ÛŒ Ø¢Ù†Ø§Ù„ÛŒØ² Ú©Ù„ÛŒÙ†ÛŒÚ©ÛŒ"):
        with st.spinner("Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªÙˆØ³Ø· Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ensemble..."):
            models, device = load_all_models()
            gray_img = img.convert('L').resize((512, 512))
            input_tensor = torch.from_numpy(np.array(gray_img)).float().unsqueeze(0).unsqueeze(0) / 255.0
            
            with torch.no_grad():
                # ØªØ±Ú©ÛŒØ¨ Ø®Ø±ÙˆØ¬ÛŒ Ø³Ù‡ Ù…Ø¯Ù„
                out = (models['general'](input_tensor) + models['specialist'](input_tensor) + models['tmj'](input_tensor)) / 3.0
            
            # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¶Ø±ÛŒØ¨ ØªØ¨Ø¯ÛŒÙ„
            pixel_size = 0.1 # Ù…Ù‚Ø¯Ø§Ø± Ù¾ÛŒØ´â€ŒÙØ±Ø¶
            if os.path.exists('mappings.csv'):
                df = pd.read_csv('mappings.csv')
                match = df[df['image_name'] == uploaded_file.name]
                if not match.empty: pixel_size = match['pixel_size'].values[0]

            pts = get_landmarks(out)
            analysis = calculate_ortho_analysis(pts, pixel_size)
            
            # Ø±Ø³Ù… Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§
            
            draw = ImageDraw.Draw(img)
            for name, p in pts.items():
                draw.ellipse((p[0]-5, p[1]-5, p[0]+5, p[1]+5), fill='red', outline='white')
            st.image(img, caption="Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø´Ø¯Ù‡", use_column_width=True)

            # Ù†Ù…Ø§ÛŒØ´ Ù†ØªØ§ÛŒØ¬ Ø¯Ø± Ú©Ø§Ø±Øªâ€ŒÙ‡Ø§ÛŒ Ø±Ù†Ú¯ÛŒ
            st.subheader("ğŸ“‹ Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ")
            c1, c2, c3 = st.columns(3)
            c1.metric("SNA", f"{analysis.get('SNA', 0):.1f}Â°")
            c2.metric("SNB", f"{analysis.get('SNB', 0):.1f}Â°")
            c3.metric("ANB", f"{analysis.get('ANB', 0):.1f}Â°")
            st.info(f"ğŸ“ Ø·ÙˆÙ„ Ù…ÙˆØ«Ø± ÙÚ© Ø¨Ø§Ù„Ø§ (McNamara): {analysis.get('McNamara_Length', 0):.2f} mm")
