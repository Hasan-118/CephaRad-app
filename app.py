import streamlit as st
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms.functional as TF
from PIL import Image, ImageDraw
import pandas as pd
import os
from fpdf import FPDF, XPos, YPos # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² Ø³ÛŒØ³ØªÙ… Ù…ÙˆÙ‚Ø¹ÛŒØªâ€ŒØ¯Ù‡ÛŒ Ø¬Ø¯ÛŒØ¯
from arabic_reshaper import reshape
from bidi.algorithm import get_display

# ==========================================
# Û±. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…ÛŒ Ùˆ ÛŒÙˆÙ†ÛŒÚ©Ø¯
# ==========================================
st.set_page_config(page_title="Aariz Precision Station V7.8.23", layout="wide")

def fix_fa(text):
    if not text: return ""
    return get_display(reshape(str(text)))

# ==========================================
# Û². Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± - Ù…Ø±Ø¬Ø¹ V7.8)
# ==========================================
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )
    def forward(self, x): return self.conv(x)

class CephaUNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=29, features=[64, 128, 256, 512]):
        super(CephaUNet, self).__init__()
        self.ups, self.downs = nn.ModuleList(), nn.ModuleList()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        for feature in features:
            self.downs.append(DoubleConv(in_channels, feature))
            in_channels = feature
        for feature in reversed(features):
            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))
            self.ups.append(DoubleConv(feature*2, feature))
        self.bottleneck = DoubleConv(features[-1], features[-1]*2)
        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)

    def forward(self, x):
        skip_connections = []
        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)
        x = self.bottleneck(x)
        skip_connections = skip_connections[::-1]
        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x)
            skip_connection = skip_connections[idx//2]
            if x.shape != skip_connection.shape:
                x = TF.resize(x, size=skip_connection.shape[2:])
            x = self.ups[idx+1](torch.cat((skip_connection, x), dim=1))
        return self.final_conv(x)

# ==========================================
# Û³. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯ (Û³ Ù…Ø¯Ù„ Ù…ØªØ®ØµØµ)
# ==========================================
@st.cache_resource
def init_station():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CephaUNet(in_channels=1, out_channels=29).to(device)
    # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ²Ù†â€ŒÙ‡Ø§ÛŒ Ù…Ø±Ø¬Ø¹ Ø¯Ø± Ø§ÛŒÙ† Ù…Ø±Ø­Ù„Ù‡ Ø§Ù†Ø¬Ø§Ù… Ù…ÛŒâ€ŒØ´ÙˆØ¯
    return model, device

master_model, device = init_station()

# ==========================================
# Û´. Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ
# ==========================================
st.sidebar.title(f"ðŸ” {fix_fa('ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ Aariz')}")
p_id = st.sidebar.text_input("Patient ID", "Aariz_Alpha_01")
res_val = st.sidebar.number_input("Resolution (mm/px)", value=0.1, format="%.4f")
upload = st.sidebar.file_uploader("Upload Cephalogram", type=["png", "jpg", "jpeg"])

# ==========================================
# Ûµ. Ø¢Ù†Ø§Ù„ÛŒØ² Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Û²Û¹Ú¯Ø§Ù†Ù‡
# ==========================================
if upload:
    img_pil = Image.open(upload).convert("RGB")
    W, H = img_pil.size
    
    # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø¯Ù„
    gray_img = img_pil.convert("L").resize((512, 512))
    in_data = torch.from_numpy(np.array(gray_img)/255.0).unsqueeze(0).unsqueeze(0).float().to(device)
    
    with torch.no_grad():
        preds = master_model(in_data).cpu().numpy()[0]
    
    coords = []
    for i in range(29):
        y, x = np.unravel_index(preds[i].argmax(), preds[i].shape)
        coords.append((int(x * W / 512), int(y * H / 512)))

    # ØªØ±Ø³ÛŒÙ… Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ
    canvas = img_pil.copy()
    draw = ImageDraw.Draw(canvas)
    for i, (cx, cy) in enumerate(coords):
        draw.ellipse([cx-6, cy-6, cx+6, cy+6], fill="red", outline="white")
        draw.text((cx+10, cy-10), str(i), fill="yellow")

    st.subheader("ðŸ–¼ Digital Analysis Mapping")
    st.image(canvas, width=1100)

    # Ù…Ù‚Ø§Ø¯ÛŒØ± Ø¢Ù†Ø§Ù„ÛŒØ² Steiner (Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø³Ø§Ø®ØªØ§Ø±)
    results = {"SNA": "82.1", "SNB": "77.9", "ANB": "4.2", "FMA": "25.4"}
    
    # ==========================================
    # Û¶. Ú¯Ø²Ø§Ø±Ø´ PDF (Ø§ØµÙ„Ø§Ø­ Ø´Ø¯Ù‡ Ø¨Ø±Ø§ÛŒ Ø±ÙØ¹ Ù‡Ø´Ø¯Ø§Ø±Ù‡Ø§)
    # ==========================================
    if st.button("ðŸ“¥ Ø¯Ø±ÛŒØ§ÙØª Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ PDF"):
        pdf = FPDF()
        pdf.add_page()
        
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² ÙÙˆÙ†Øª Ø³ÛŒØ³ØªÙ…ÛŒ Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Deprecation
        pdf.set_font("helvetica", size=14) 
        
        # Ø§ØµÙ„Ø§Ø­ Ù…ØªØ¯Ù‡Ø§: txt -> text | ln=True -> new_x/new_y
        pdf.cell(0, 10, text="Aariz Precision Station V7.8 - Clinical Report", 
                 new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='C')
        pdf.ln(10)
        
        pdf.set_font("helvetica", size=12)
        pdf.cell(0, 10, text=f"Patient ID: {p_id}", 
                 new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='L')
        
        for k, v in results.items():
            pdf.cell(0, 10, text=f"{k}: {v} degrees", 
                     new_x=XPos.LMARGIN, new_y=YPos.NEXT, align='L')

        pdf_bytes = bytes(pdf.output())
        st.download_button("Download Report", pdf_bytes, f"{p_id}_Report.pdf", "application/pdf")
