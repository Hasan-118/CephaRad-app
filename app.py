import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import os
import gdown
from PIL import Image, ImageDraw
import torchvision.transforms as transforms
from streamlit_image_coordinates import streamlit_image_coordinates

# --- Û±. Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ø±Ø¬Ø¹ Aariz (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±) ---
class DoubleConv(nn.Module):
    def __init__(self, in_ch, out_ch, dropout_prob=0.1):
        super().__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True), nn.Dropout2d(p=dropout_prob),
            nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch),
            nn.ReLU(inplace=True)
        )
    def forward(self, x): return self.conv(x)

class CephaUNet(nn.Module):
    def __init__(self, n_landmarks=29):
        super().__init__()
        self.inc = DoubleConv(1, 64); self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(64, 128))
        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(128, 256))
        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(256, 512, dropout_prob=0.3))
        self.up1 = nn.ConvTranspose2d(512, 256, 2, stride=2); self.conv_up1 = DoubleConv(512, 256, dropout_prob=0.3)
        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2); self.conv_up2 = DoubleConv(256, 128)
        self.up3 = nn.ConvTranspose2d(128, 64, 2, stride=2); self.conv_up3 = DoubleConv(128, 64)
        self.outc = nn.Conv2d(64, n_landmarks, kernel_size=1)
    def forward(self, x):
        x1 = self.inc(x); x2 = self.down1(x1); x3 = self.down2(x2); x4 = self.down3(x3)
        x = self.up1(x4); x = torch.cat([x, x3], dim=1); x = self.conv_up1(x)
        x = self.up2(x); x = torch.cat([x, x2], dim=1); x = self.conv_up2(x)
        x = self.up3(x); x = torch.cat([x, x1], dim=1); x = self.conv_up3(x)
        return self.outc(x)

# --- Û². Ù„ÙˆØ¯Ø± Ùˆ ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---
@st.cache_resource
def load_aariz_models():
    model_ids = {
        'checkpoint_unet_clinical.pth': '1a1sZ2z0X6mOwljhBjmItu_qrWYv3v_ks',
        'specialist_pure_model.pth': '1RakXVfUC_ETEdKGBi6B7xOD7MjD59jfU',
        'tmj_specialist_model.pth': '1tizRbUwf7LgC6Radaeiz6eUffiwal0cH'
    }
    device = torch.device("cpu")
    loaded_models = []
    for f, fid in model_ids.items():
        if not os.path.exists(f): gdown.download(f'https://drive.google.com/uc?id={fid}', f, quiet=True)
        try:
            m = CephaUNet(n_landmarks=29).to(device)
            ckpt = torch.load(f, map_location=device)
            state = ckpt['model_state_dict'] if 'model_state_dict' in ckpt else ckpt
            m.load_state_dict({k.replace('module.', ''): v for k, v in state.items()}, strict=False)
            m.eval(); loaded_models.append(m)
        except: pass
    return loaded_models, device

def run_precise_prediction(img_pil, models, device):
    ow, oh = img_pil.size
    img_gray = img_pil.convert('L')
    ratio = 512 / max(ow, oh)
    nw, nh = int(ow * ratio), int(oh * ratio)
    img_rs = img_gray.resize((nw, nh), Image.LANCZOS)
    canvas = Image.new("L", (512, 512))
    px, py = (512 - nw) // 2, (512 - nh) // 2
    canvas.paste(img_rs, (px, py))
    input_tensor = transforms.ToTensor()(canvas).unsqueeze(0).to(device)
    with torch.no_grad(): outs = [m(input_tensor)[0].cpu().numpy() for m in models]
    ANT_IDX, POST_IDX = [10, 14, 9, 5, 28, 20], [7, 11, 12, 15]
    coords = {}
    for i in range(29):
        hm = outs[1][i] if i in ANT_IDX else (outs[2][i] if i in POST_IDX else outs[0][i])
        y, x = np.unravel_index(np.argmax(hm), hm.shape)
        coords[i] = [int((x - px) / ratio), int((y - py) / ratio)]
    return coords

# --- Û³. Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¢Ù†Ø§Ù„ÛŒØ² Wits ---
def calculate_wits(l_dict):
    # Wits Ù†ÛŒØ§Ø² Ø¨Ù‡ ØµÙØ­Ù‡ Occlusal Ø¯Ø§Ø±Ø¯ (Ù…Ø«Ù„Ø§Ù‹ Ø¨ÛŒÙ† Ø¯Ù†Ø¯Ø§Ù†â€ŒÙ‡Ø§ÛŒ Ù…ÙˆÙ„Ø± Ùˆ Ø«Ù†Ø§ÛŒØ§)
    # Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ±Ø¯ Ù†ÛŒØ§Ø²: UMT (22) Ùˆ LMT (18) Ø¨Ø±Ø§ÛŒ Ø®Ù„ÙØŒ Ùˆ ØªÙ…Ø§Ø³ Ø¯Ù†Ø¯Ø§Ù†ÛŒ UIT/LIT Ø¨Ø±Ø§ÛŒ Ù‚Ø¯Ø§Ù…
    # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ Ø§Ø² Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù…ÙˆÙ„Ø±Ù‡Ø§ Ùˆ Ø«Ù†Ø§ÛŒØ§ Ø¨Ø±Ø§ÛŒ Ø±Ø³Ù… Ø®Ø· Ø§Ù¾ÛŒÚ©Ø§Ù„ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
    try:
        p1 = np.array(l_dict[22]) # Upper Molar
        p2 = np.array(l_dict[21]) # Upper Incisor Tip
        
        # Ø®Ø· Occlusal (L)
        v = p2 - p1
        v_unit = v / np.linalg.norm(v)
        
        # Ù†Ù‚Ø§Ø· A (0) Ùˆ B (2)
        A = np.array(l_dict[0])
        B = np.array(l_dict[2])
        
        # ØªØµÙˆÛŒØ± Ú©Ø±Ø¯Ù† Ù†Ù‚Ø§Ø· Ø¨Ø± Ø®Ø· (Projection)
        # AO = p1 + dot(A-p1, v_unit) * v_unit
        dist_a = np.dot(A - p1, v_unit)
        dist_b = np.dot(B - p1, v_unit)
        
        wits_value = dist_a - dist_b # AO - BO
        return round(wits_value, 2), p1, p2
    except:
        return 0, None, None

# --- Û´. Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ (UI) ---
st.set_page_config(page_title="Aariz Precision Station V4.9", layout="wide")
models, device = load_aariz_models()
landmark_names = ['A', 'ANS', 'B', 'Me', 'N', 'Or', 'Pog', 'PNS', 'Pn', 'R', 'S', 'Ar', 'Co', 'Gn', 'Go', 'Po', 'LPM', 'LIT', 'LMT', 'UPM', 'UIA', 'UIT', 'UMT', 'LIA', 'Li', 'Ls', 'N`', 'Pog`', 'Sn']

if "click_version" not in st.session_state: st.session_state.click_version = 0
if "last_target" not in st.session_state: st.session_state.last_target = 0

text_scale = st.sidebar.slider("ðŸ”¤ Ù…Ù‚ÛŒØ§Ø³ Ø§Ø¨Ø¹Ø§Ø¯ Ù†Ø§Ù… (Font Scale):", 1, 10, 3)
uploaded_file = st.sidebar.file_uploader("Ø¢Ù¾Ù„ÙˆØ¯ ØªØµÙˆÛŒØ± Ø³ÙØ§Ù„ÙˆÙ…ØªØ±ÛŒ:", type=['png', 'jpg', 'jpeg'])

if uploaded_file and len(models) == 3:
    raw_img = Image.open(uploaded_file).convert("RGB")
    W, H = raw_img.size
    
    if "lms" not in st.session_state or st.session_state.get("file_id") != uploaded_file.name:
        st.session_state.initial_lms = run_precise_prediction(raw_img, models, device)
        st.session_state.lms = st.session_state.initial_lms.copy()
        st.session_state.file_id = uploaded_file.name

    target_idx = st.sidebar.selectbox("ðŸŽ¯ Ø§Ù†ØªØ®Ø§Ø¨ Ù„Ù†Ø¯Ù…Ø§Ø±Ú© ÙØ¹Ø§Ù„:", range(29), format_func=lambda x: f"{x}: {landmark_names[x]}")
    
    if st.sidebar.button("ðŸ”„ Reset Current Point"):
        st.session_state.lms[target_idx] = st.session_state.initial_lms[target_idx].copy()
        st.session_state.click_version += 1
        st.rerun()

    if st.session_state.last_target != target_idx:
        st.session_state.click_version += 1
        st.session_state.last_target = target_idx
        st.rerun()

    col1, col2 = st.columns([1.2, 2.5])
    
    with col1:
        st.subheader("ðŸ” Micro-Adjustment")
        l_pos = st.session_state.lms[target_idx]
        size_m = 180 
        left, top = max(0, min(int(l_pos[0]-size_m//2), W-size_m)), max(0, min(int(l_pos[1]-size_m//2), H-size_m))
        mag_crop = raw_img.crop((left, top, left+size_m, top+size_m)).resize((400, 400), Image.LANCZOS)
        mag_draw = ImageDraw.Draw(mag_crop)
        mag_draw.line((180, 200, 220, 200), fill="red", width=3); mag_draw.line((200, 180, 200, 220), fill="red", width=3)
        res_mag = streamlit_image_coordinates(mag_crop, key=f"mag_{target_idx}_{st.session_state.click_version}")
        if res_mag:
            scale_mag = size_m / 400
            new_c = [int(left + (res_mag["x"] * scale_mag)), int(top + (res_mag["y"] * scale_mag))]
            if st.session_state.lms[target_idx] != new_c:
                st.session_state.lms[target_idx] = new_c
                st.session_state.click_version += 1
                st.rerun()

    with col2:
        st.subheader("ðŸ–¼ Ù†Ù…Ø§ÛŒ Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ (Steiner + Wits)")
        draw_img = raw_img.copy()
        draw = ImageDraw.Draw(draw_img)
        l = st.session_state.lms
        
        # Steiner Lines
        if all(k in l for k in [10, 4, 0, 2]):
            draw.line([tuple(l[10]), tuple(l[4])], fill="yellow", width=3) # S-N
            draw.line([tuple(l[4]), tuple(l[0])], fill="cyan", width=2) # N-A
            draw.line([tuple(l[4]), tuple(l[2])], fill="magenta", width=2) # N-B

        # Wits Occlusal Line
        w_val, p_back, p_front = calculate_wits(l)
        if p_back is not None:
            # Ø§Ù…ØªØ¯Ø§Ø¯ Ø®Ø· Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¨Ù‡ØªØ±
            draw.line([tuple(p_back), tuple(p_front)], fill="white", width=2)

        for i, pos in l.items():
            is_act = (i == target_idx)
            color = (255, 0, 0) if is_act else (0, 255, 0)
            r = 10 if is_act else 6
            draw.ellipse([pos[0]-r, pos[1]-r, pos[0]+r, pos[1]+r], fill=color, outline="white", width=2)
            
            name_text = landmark_names[i]
            temp_txt = Image.new('RGBA', (len(name_text)*8, 12), (0,0,0,0))
            temp_draw = ImageDraw.Draw(temp_txt)
            temp_draw.text((0, 0), name_text, fill=color)
            new_w, new_h = int(temp_txt.width * text_scale), int(temp_txt.height * text_scale)
            scaled_txt = temp_txt.resize((new_w, new_h), Image.NEAREST)
            draw_img.paste(scaled_txt, (pos[0]+r+10, pos[1]-r), scaled_txt)

        res_main = streamlit_image_coordinates(draw_img, width=850, key=f"main_{st.session_state.click_version}")
        if res_main:
            c_scale = W / 850
            m_c = [int(res_main["x"] * c_scale), int(res_main["y"] * c_scale)]
            if st.session_state.lms[target_idx] != m_c:
                st.session_state.lms[target_idx] = m_c
                st.session_state.click_version += 1
                st.rerun()

    # --- Calculations ---
    st.divider()
    def get_ang(p1, p2, p3):
        v1, v2 = np.array(p1)-np.array(p2), np.array(p3)-np.array(p2)
        norm = np.linalg.norm(v1)*np.linalg.norm(v2)
        return round(np.degrees(np.arccos(np.clip(np.dot(v1,v2)/(norm if norm>0 else 1), -1, 1))), 2)

    sna = get_ang(l[10], l[4], l[0])
    snb = get_ang(l[10], l[4], l[2])
    
    c1, c2, c3, c4 = st.columns(4)
    c1.metric("SNA", f"{sna}Â°")
    c2.metric("SNB", f"{snb}Â°")
    c3.metric("ANB", f"{round(sna-snb, 2)}Â°")
    c4.metric("Wits Appraisal", f"{w_val} px")
    
    st.info("ðŸ’¡ Ù…Ù‚Ø¯Ø§Ø± Wits Ø¯Ø± Ø­Ø§Ù„ Ø­Ø§Ø¶Ø± Ø¨Ø± Ø§Ø³Ø§Ø³ Ù¾ÛŒÚ©Ø³Ù„ Ú¯Ø²Ø§Ø±Ø´ Ø´Ø¯Ù‡ Ø§Ø³Øª. Ù¾Ø³ Ø§Ø² Ú©Ø§Ù„ÛŒØ¨Ø±Ø§Ø³ÛŒÙˆÙ† Ø¨Ø§ Ø®Ø·â€ŒÚ©Ø´ØŒ Ø¨Ù‡ Ù…ÛŒÙ„ÛŒâ€ŒÙ…ØªØ± ØªØ¨Ø¯ÛŒÙ„ Ø®ÙˆØ§Ù‡Ø¯ Ø´Ø¯.")
