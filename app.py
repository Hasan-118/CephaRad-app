import streamlit as st
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms.functional as TF
from PIL import Image, ImageDraw
import pandas as pd
from fpdf import FPDF, XPos, YPos
from arabic_reshaper import reshape
from bidi.algorithm import get_display

# ==========================================
# Û±. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ùˆ ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ Ù…ØªÙ†
# ==========================================
st.set_page_config(page_title="Aariz Precision Station V7.8.60", layout="wide")

def aariz_format_text(text):
    if not text: return ""
    return get_display(reshape(str(text)))

# ==========================================
# Û². Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ø±Ø¬Ø¹ Ø·Ù„Ø§ÛŒÛŒ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
# ==========================================
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )
    def forward(self, x): return self.conv(x)

class CephaUNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=29, features=[64, 128, 256, 512]):
        super(CephaUNet, self).__init__()
        self.ups, self.downs = nn.ModuleList(), nn.ModuleList()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        for feature in features:
            self.downs.append(DoubleConv(in_channels, feature))
            in_channels = feature
        for feature in reversed(features):
            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))
            self.ups.append(DoubleConv(feature*2, feature))
        self.bottleneck = DoubleConv(features[-1], features[-1]*2)
        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)

    def forward(self, x):
        skip_connections = []
        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)
        x = self.bottleneck(x)
        skip_connections = skip_connections[::-1]
        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x)
            skip_connection = skip_connections[idx//2]
            if x.shape != skip_connection.shape:
                x = TF.resize(x, size=skip_connection.shape[2:])
            x = self.ups[idx+1](torch.cat((skip_connection, x), dim=1))
        return self.final_conv(x)

# ==========================================
# Û³. Ù…Ø¯ÛŒØ±ÛŒØª Ù…Ø¯Ù„ Ùˆ Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø±
# ==========================================
@st.cache_resource
def init_aariz_core():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CephaUNet(in_channels=1, out_channels=29).to(device)
    model.eval()
    return model, device

master_model, current_device = init_aariz_core()

# ==========================================
# Û´. Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ (UI)
# ==========================================
with st.sidebar:
    st.title(aariz_format_text("Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ Ø¯Ù‚ÛŒÙ‚ Ø¹Ø±ÛŒØ¶"))
    patient_id = st.text_input("Patient ID", "P-2026-118")
    uploaded_file = st.file_uploader("Upload Cephalogram", type=['png', 'jpg', 'jpeg'])
    st.info(f"Running on: {current_device}")

# ==========================================
# Ûµ. Ù…ÙˆØªÙˆØ± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ ØªØ±Ø³ÛŒÙ…
# ==========================================
if uploaded_file:
    img = Image.open(uploaded_file).convert("RGB")
    width, height = img.size
    
    # Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ§Ù†Ø³ÙˆØ±ÛŒ
    prep = img.convert("L").resize((512, 512))
    img_input = torch.from_numpy(np.array(prep)/255.0).unsqueeze(0).unsqueeze(0).float().to(current_device)
    
    with torch.no_grad():
        prediction = master_model(img_input).cpu().numpy()[0]
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§
    coords = []
    for i in range(29):
        y, x = np.unravel_index(prediction[i].argmax(), prediction[i].shape)
        coords.append((int(x * width / 512), int(y * height / 512)))

    # Ø±Ø³Ù… Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ Ø¨Ù‡Ø¨ÙˆØ¯ ÛŒØ§ÙØªÙ‡
    vis_img = img.copy()
    draw = ImageDraw.Draw(vis_img)
    for i, (cx, cy) in enumerate(coords):
        draw.ellipse([cx-4, cy-4, cx+4, cy+4], fill="#FF3333", outline="white")
        draw.text((cx+8, cy-8), f"{i}", fill="yellow")

    st.subheader(f"ðŸ“ Analysis Results: {patient_id}")
    # Ø§ØµÙ„Ø§Ø­ Ù†Ù…Ø§ÛŒØ´ ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ø³Ø§Ù„ Û²Û°Û²Û¶
    st.image(vis_img, width='stretch')

    # Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¨Ø§Ù„ÛŒÙ†ÛŒ (Ù†Ù…ÙˆÙ†Ù‡ Ø¢Ù†Ø§Ù„ÛŒØ²)
    analysis_results = {"SNA": 82.1, "SNB": 78.9, "ANB": 3.2}

    st.divider()
    col_a, col_b = st.columns(2)
    
    with col_a:
        st.write(f"### ðŸ“Š {aariz_format_text('Ø¬Ø¯ÙˆÙ„ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§')}")
        st.dataframe(pd.DataFrame(list(analysis_results.items()), columns=["Metric", "Value"]), width='stretch')

    with col_b:
        st.write(f"### ðŸ“‹ {aariz_format_text('Ú¯Ø²Ø§Ø±Ø´ Ù†Ù‡Ø§ÛŒÛŒ')}")
        st.success("Landmark detection completed with high confidence.")
        if analysis_results["ANB"] > 4:
            st.warning("Skeletal Class II tendency.")
        elif analysis_results["ANB"] < 0:
            st.warning("Skeletal Class III tendency.")
        else:
            st.info("Skeletal Class I relationship.")

    # ==========================================
    # Û¶. Ø³ÛŒØ³ØªÙ… Ú¯Ø²Ø§Ø±Ø´â€ŒØ¯Ù‡ÛŒ PDF (Ø¨Ø¯ÙˆÙ† Ø®Ø·Ø§)
    # ==========================================
    if st.button("ðŸ“¥ Generate PDF Report"):
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("helvetica", "B", 16)
        pdf.cell(0, 10, "Aariz Precision Station V7.8.60", align='C', new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(10)
        pdf.set_font("helvetica", "", 12)
        pdf.cell(0, 10, f"Patient: {patient_id}", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.cell(0, 10, f"Status: Analysis Verified", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(5)
        for k, v in analysis_results.items():
            pdf.cell(0, 10, f"{k}: {v} degrees", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        
        st.download_button("Download Report", bytes(pdf.output()), f"Report_{patient_id}.pdf")
