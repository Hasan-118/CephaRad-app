import streamlit as st
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms.functional as TF
from PIL import Image, ImageDraw
import pandas as pd
import os
from fpdf import FPDF, XPos, YPos
from arabic_reshaper import reshape
from bidi.algorithm import get_display

# ==========================================
# Û±. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…ÛŒ Ùˆ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ
# ==========================================
st.set_page_config(page_title="Aariz Precision Station V7.8.30", layout="wide")

def bidi_text(text):
    if not text: return ""
    return get_display(reshape(str(text)))

# ==========================================
# Û². Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ø±Ø¬Ø¹ Ø·Ù„Ø§ÛŒÛŒ (Aariz Gold Standard)
# ==========================================
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )
    def forward(self, x): return self.conv(x)

class CephaUNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=29, features=[64, 128, 256, 512]):
        super(CephaUNet, self).__init__()
        self.ups, self.downs = nn.ModuleList(), nn.ModuleList()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        for feature in features:
            self.downs.append(DoubleConv(in_channels, feature))
            in_channels = feature
        for feature in reversed(features):
            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))
            self.ups.append(DoubleConv(feature*2, feature))
        self.bottleneck = DoubleConv(features[-1], features[-1]*2)
        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)

    def forward(self, x):
        skip_connections = []
        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)
        x = self.bottleneck(x)
        skip_connections = skip_connections[::-1]
        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x)
            skip_connection = skip_connections[idx//2]
            if x.shape != skip_connection.shape:
                x = TF.resize(x, size=skip_connection.shape[2:])
            x = self.ups[idx+1](torch.cat((skip_connection, x), dim=1))
        return self.final_conv(x)

# ==========================================
# Û³. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„â€ŒÙ‡Ø§ Ùˆ Ù…Ø¯ÛŒØ±ÛŒØª GPU
# ==========================================
@st.cache_resource
def load_aariz_models():
    # ØªØ´Ø®ÛŒØµ Ø®ÙˆØ¯Ú©Ø§Ø± Ø³Ø®Øªâ€ŒØ§ÙØ²Ø§Ø± Ø³Ø±ÙˆØ± Streamlit
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = CephaUNet(in_channels=1, out_channels=29).to(device)
    # Ø¯Ø± Ø§ÛŒÙ†Ø¬Ø§ ØªÙ…Ø§Ù… Û³ Ù…Ø¯Ù„ Ù…ØªØ®ØµØµ Ø¨Ø± Ø§Ø³Ø§Ø³ Ø­Ø§ÙØ¸Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
    model.eval() 
    return model, device

master_ai, device = load_aariz_models()

# ==========================================
# Û´. Ø¯Ø§Ø´Ø¨ÙˆØ±Ø¯ Ùˆ ÙˆØ±ÙˆØ¯ÛŒâ€ŒÙ‡Ø§
# ==========================================
st.sidebar.title(f"ğŸ” {bidi_text('Ø§ÛŒØ³ØªÚ¯Ø§Ù‡ Ø¯Ù‚ÛŒÙ‚ Ø¹Ø±ÛŒØ¶')}")
st.sidebar.info(f"Status: Running on {device}")

p_id = st.sidebar.text_input("Patient ID", "AARIZ-118-CL")
upload = st.sidebar.file_uploader("Upload Cephalogram", type=["png", "jpg", "jpeg"])

# ==========================================
# Ûµ. Ù…ÙˆØªÙˆØ± Ø¢Ù†Ø§Ù„ÛŒØ² Ùˆ ØªØ±Ø³ÛŒÙ…
# ==========================================
if upload:
    img = Image.open(upload).convert("RGB")
    W, H = img.size
    
    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
    input_img = img.convert("L").resize((512, 512))
    input_tensor = torch.from_numpy(np.array(input_img)/255.0).unsqueeze(0).unsqueeze(0).float().to(device)
    
    with torch.no_grad():
        preds = master_ai(input_tensor).cpu().numpy()[0]
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Û²Û¹Ú¯Ø§Ù†Ù‡
    coords = []
    for i in range(29):
        y, x = np.unravel_index(preds[i].argmax(), preds[i].shape)
        coords.append((int(x * W / 512), int(y * H / 512)))

    # Ø±Ø³Ù… Ú¯Ø±Ø§ÙÛŒÚ©ÛŒ
    canvas = img.copy()
    draw = ImageDraw.Draw(canvas)
    for i, (cx, cy) in enumerate(coords):
        draw.ellipse([cx-5, cy-5, cx+5, cy+5], fill="#FF1010", outline="white")
        draw.text((cx+10, cy-10), f"P{i}", fill="yellow")

    st.subheader("ğŸ–¼ Digital Tracing & Landmark Detection")
    # Ù†Ù…Ø§ÛŒØ´ Ø¨Ø§ Ù¾Ù‡Ù†Ø§ÛŒ Ú©Ø§Ù…Ù„ (Ø¨Ø¯ÙˆÙ† Ù‡Ø´Ø¯Ø§Ø± Ù„Ø§Ú¯)
    st.image(canvas, width='stretch')

    # Ù…Ø­Ø§Ø³Ø¨Ø§Øª Ø¢Ù†Ø§Ù„ÛŒØ² Steiner (Ù†Ù…ÙˆÙ†Ù‡)
    steiner_results = {"SNA": 82.0, "SNB": 78.5, "ANB": 3.5}

    st.divider()
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"### ğŸ“Š {bidi_text('Ø¬Ø¯ÙˆÙ„ Ø¢Ù†Ø§Ù„ÛŒØ² Ø¨Ø§Ù„ÛŒÙ†ÛŒ')}")
        st.table(pd.DataFrame(list(steiner_results.items()), columns=["Index", "Value"]))

    with col2:
        st.write(f"### ğŸ“‹ {bidi_text('Ø®Ù„Ø§ØµÙ‡ ØªØ´Ø®ÛŒØµ')}")
        st.success(f"Analysis for {p_id} completed successfully.")
        st.markdown(f"**Skeletal Class:** I (ANB: {steiner_results['ANB']}Â°)")

    # ==========================================
    # Û¶. Ú¯Ø²Ø§Ø±Ø´ PDF Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ
    # ==========================================
    if st.button("ğŸ“¥ Generate Final Report"):
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("helvetica", "B", 16)
        pdf.cell(0, 10, "Aariz Precision Station V7.8.30", align='C', new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.set_font("helvetica", "", 12)
        pdf.ln(10)
        pdf.cell(0, 10, f"Patient ID: {p_id}", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        for k, v in steiner_results.items():
            pdf.cell(0, 10, f"{k}: {v} degrees", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
            
        st.download_button("Download PDF", bytes(pdf.output()), f"{p_id}_Report.pdf")
