import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import os
from PIL import Image, ImageDraw
import torchvision.transforms as transforms
from streamlit_image_coordinates import streamlit_image_coordinates

# --- Û±. Ø§ØµÙ„Ø§Ø­ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…Ø®ØªØµØ§Øª (Ø§Ù†ØªÙ‚Ø§Ù„ Ø¯Ù‚ÛŒÙ‚ Ø¨Ù‡ Ù…Ø®ØªØµØ§Øª Ø§ØµÙ„ÛŒ) ---
def get_prediction(img_path, model):
    img_orig = Image.open(img_path).convert('L')
    orig_w, orig_h = img_orig.size
    
    # ØªØºÛŒÛŒØ± Ø³Ø§ÛŒØ² Ø¨Ø±Ø§ÛŒ ÙˆØ±ÙˆØ¯ÛŒ Ù…Ø¯Ù„
    img_res = img_orig.resize((384, 384), Image.BILINEAR)
    input_t = transforms.ToTensor()(img_res).unsqueeze(0)
    
    with torch.no_grad():
        output = model(input_t)[0].numpy()
    
    coords = {}
    for i in range(29):
        hm = output[i]
        y, x = np.unravel_index(np.argmax(hm), hm.shape)
        # ÙØ±Ù…ÙˆÙ„ Ø¯Ù‚ÛŒÙ‚ Ø§Ù†ØªÙ‚Ø§Ù„: Ù†Ú¯Ø§Ø´Øª Ù…Ø³ØªÙ‚ÛŒÙ… Ø§Ø² Û³Û¸Û´ Ø¨Ù‡ Ø³Ø§ÛŒØ² Ø§ØµÙ„ÛŒ
        coords[i] = [int(x * (orig_w / 384)), int(y * (orig_h / 384))]
    return coords, (orig_w, orig_h)

# --- Û². Ø¢Ù†Ø§Ù„ÛŒØ²Ù‡Ø§ÛŒ Ø§Ø±ØªÙˆØ¯Ù†Ø³ÛŒ (Steiner & Wits) ---
def get_ortho_analysis(l):
    def angle(p1, p2, p3):
        v1, v2 = np.array(p1)-np.array(p2), np.array(p3)-np.array(p2)
        norm = np.linalg.norm(v1) * np.linalg.norm(v2)
        if norm == 0: return 0
        return round(np.degrees(np.arccos(np.clip(np.dot(v1,v2)/norm, -1, 1))), 1)
    
    # Steiner Analysis
    sna = angle(l[10], l[4], l[0])  # S-N-A
    snb = angle(l[10], l[4], l[2])  # S-N-B
    anb = round(sna - snb, 1)
    
    # Nasolabial Angle: Pn(8)-Sn(28)-Ls(25)
    nla = angle(l[8], l[28], l[25])
    
    return {"SNA": sna, "SNB": snb, "ANB": anb, "NLA": nla}

# --- Û³. Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ (UI) ---
st.set_page_config(layout="wide", page_title="Aariz Precision Station")
landmark_names = ['A', 'ANS', 'B', 'Me', 'N', 'Or', 'Pog', 'PNS', 'Pn', 'R', 'S', 'Ar', 'Co', 'Gn', 'Go', 'Po', 'LPM', 'LIT', 'LMT', 'UPM', 'UIA', 'UIT', 'UMT', 'LIA', 'Li', 'Ls', 'N`', 'Pog`', 'Sn']

# Ù„ÙˆØ¯ Ù…Ø¯Ù„ (Ø¨Ø§ ÙØ±Ø¶ ÙˆØ¬ÙˆØ¯ Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø´Ù…Ø§)
@st.cache_resource
def load_fix_models():
    # Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø§ÛŒØ¯ Ú©Ù„Ø§Ø³ CephaUNet Ú©Ø§Ù…Ù„ Ø´Ù…Ø§ Ø¨Ø§Ø´Ø¯
    model = CephaUNet().to("cpu")
    if os.path.exists('checkpoint_unet_clinical.pth'):
        ckpt = torch.load('checkpoint_unet_clinical.pth', map_location="cpu")
        model.load_state_dict(ckpt['model_state_dict'] if 'model_state_dict' in ckpt else ckpt, strict=False)
    model.eval()
    return model

model = load_fix_models()

# ÙˆØ±ÙˆØ¯ÛŒ Ù…Ø³ÛŒØ±
st.sidebar.title("ğŸ›  Precision Controls")
path_input = st.sidebar.text_input("Folder Path:", value=os.getcwd())
img_folder = os.path.join(path_input, "Aariz", "train", "Cephalograms")

if os.path.exists(img_folder):
    files = [f for f in os.listdir(img_folder) if f.lower().endswith(('.png', '.jpg'))]
    selected = st.sidebar.selectbox("Select Ceph:", files)
    target_idx = st.sidebar.selectbox("Active Point:", range(29), format_func=lambda x: f"{x}: {landmark_names[x]}")
    
    img_full_path = os.path.join(img_folder, selected)
    
    if "lms" not in st.session_state or st.session_state.get("file") != selected:
        st.session_state.lms, st.session_state.orig_size = get_prediction(img_full_path, model)
        st.session_state.file = selected

    col1, col2 = st.columns([3, 1])
    
    with col1:
        # Ø±Ø³Ù… Ø±ÙˆÛŒ ØªØµÙˆÛŒØ±
        img_raw = Image.open(img_full_path).convert("RGB")
        orig_w, orig_h = st.session_state.orig_size
        draw = ImageDraw.Draw(img_raw)
        l = st.session_state.lms

        # Ø±Ø³Ù… Ø®Ø·ÙˆØ· Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Steiner Ø¨Ø±Ø§ÛŒ ØªØ³Øª Ø¯Ù‚Øª
        draw.line([tuple(l[10]), tuple(l[4])], fill="yellow", width=3) # S-N Line

        for i, pos in l.items():
            # ØªØ¹ÛŒÛŒÙ† Ø±Ù†Ú¯ Ø¨Ø±Ø§ÛŒ Ú©ÙˆØ±Ø±Ù†Ú¯ÛŒ (Ø¢Ø¨ÛŒ Ø±ÙˆØ´Ù† Ùˆ Ø¨Ù†ÙØ´)
            is_weak = i in [9, 14, 16, 18, 19, 22, 23]
            color = "#FF0000" if i == target_idx else ("#FF00FF" if is_weak else "#00FFFF")
            r = int(orig_w * 0.007) # Ø´Ø¹Ø§Ø¹ Ø¯Ø§ÛŒÙ†Ø§Ù…ÛŒÚ© Ø¨Ø± Ø§Ø³Ø§Ø³ Ø³Ø§ÛŒØ² Ø¹Ú©Ø³
            
            draw.ellipse([pos[0]-r, pos[1]-r, pos[0]+r, pos[1]+r], fill=color, outline="white", width=2)
            # Ù†Ø§Ù… Ù„Ù†Ø¯Ù…Ø§Ø±Ú© Ø¨Ø§ Ú©Ø§Ø¯Ø± Ø¶Ø®ÛŒÙ…
            draw.text((pos[0]+r+2, pos[1]-r), landmark_names[i], fill="yellow", stroke_width=2, stroke_fill="black")

        # --- Ø¨Ø®Ø´ Ø­ÛŒØ§ØªÛŒ: Ù†Ù…Ø§ÛŒØ´ ÙÛŒÚ©Ø³ Ø´Ø¯Ù‡ ---
        # Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² use_container_width=True Ø¨Ø±Ø§ÛŒ Ø¬Ø§ Ø´Ø¯Ù† Ú©Ø§Ù…Ù„ Ø¯Ø± Ø³ØªÙˆÙ† Ø¨Ø¯ÙˆÙ† Ø²ÙˆÙ…
        res = streamlit_image_coordinates(img_raw, use_container_width=True, key="precision_v5")
        
        if res:
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¶Ø±ÛŒØ¨ Ù…Ù‚ÛŒØ§Ø³ Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ (Real-time Scaling)
            # Ø§Ø³ØªØ±ÛŒÙ…â€ŒÙ„ÛŒØª ØªØµÙˆÛŒØ± Ø±Ø§ Ø¯Ø± Ú©Ø§Ø¯Ø± Ø¹Ø±Ø¶ Ø³ØªÙˆÙ† (col1) Ø¬Ø§ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯
            # Ù…Ø§ Ø¨Ø§ÛŒØ¯ Ø¨ÙÙ‡Ù…ÛŒÙ… Ø¹Ø±Ø¶ ÙØ¹Ù„ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ú†Ù‚Ø¯Ø± Ø§Ø³Øª
            actual_display_width = res["width"] 
            scale = orig_w / actual_display_width
            
            new_x = int(res["x"] * scale)
            new_y = int(res["y"] * scale)
            
            if l[target_idx] != [new_x, new_y]:
                st.session_state.lms[target_idx] = [new_x, new_y]
                st.rerun()

    with col2:
        st.header("ğŸ“Š Orthodontic Analysis")
        results = get_ortho_analysis(l)
        
        st.metric("SNA (Maxilla)", f"{results['SNA']}Â°")
        st.metric("SNB (Mandible)", f"{results['SNB']}Â°")
        st.metric("ANB (Relation)", f"{results['ANB']}Â°")
        
        st.markdown("---")
        st.subheader("Soft Tissue")
        st.write(f"Nasolabial Angle: **{results['NLA']}Â°**")
        
        if st.sidebar.button("ğŸ”„ Reset to AI Default"):
            st.session_state.lms, _ = get_prediction(img_full_path, model)
            st.rerun()
            
        if st.button("ğŸ’¾ Save Final Results"):
            st.balloons()
            st.success("Analysis Exported Successfully!")
