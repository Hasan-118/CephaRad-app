import streamlit as st
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms.functional as TF
from PIL import Image, ImageDraw
import pandas as pd
from fpdf import FPDF, XPos, YPos
from arabic_reshaper import reshape
from bidi.algorithm import get_display

# ==========================================
# Û±. Ù…Ø¯ÛŒØ±ÛŒØª ÙÙˆÙ†Øª Ùˆ Ø¸Ø§Ù‡Ø± (UI/UX)
# ==========================================
st.set_page_config(page_title="Aariz Precision Station V7.8.80", layout="wide")

def aariz_font_engine(text):
    if not text: return ""
    return get_display(reshape(str(text)))

# ==========================================
# Û². Ù…Ø¹Ù…Ø§Ø±ÛŒ Ù…Ø±Ø¬Ø¹ Ø·Ù„Ø§ÛŒÛŒ V7.8.16 (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ±)
# ==========================================
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )
    def forward(self, x): return self.conv(x)

class CephaUNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=29, features=[64, 128, 256, 512]):
        super(CephaUNet, self).__init__()
        self.ups, self.downs = nn.ModuleList(), nn.ModuleList()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        for feature in features:
            self.downs.append(DoubleConv(in_channels, feature))
            in_channels = feature
        for feature in reversed(features):
            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))
            self.ups.append(DoubleConv(feature*2, feature))
        self.bottleneck = DoubleConv(features[-1], features[-1]*2)
        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)

    def forward(self, x):
        skip_connections = []
        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)
        x = self.bottleneck(x)
        skip_connections = skip_connections[::-1]
        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x)
            skip_connection = skip_connections[idx//2]
            if x.shape != skip_connection.shape:
                x = TF.resize(x, size=skip_connection.shape[2:])
            x = self.ups[idx+1](torch.cat((skip_connection, x), dim=1))
        return self.final_conv(x)

# ==========================================
# Û³. Ù…Ø¯ÛŒØ±ÛŒØª Ø¨Ù‡ÛŒÙ†Ù‡ Ø­Ø§ÙØ¸Ù‡ Ùˆ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„
# ==========================================
@st.cache_resource
def load_gold_model():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # Ù…Ø¯Ù„ Ù…Ø±Ø¬Ø¹ Û²Û¹ Ù†Ù‚Ø·Ù‡â€ŒØ§ÛŒ Ø·Ø¨Ù‚ Ø¢Ù…ÙˆØ²Ø´â€ŒÙ‡Ø§ÛŒ Ù‚Ø¨Ù„ÛŒ
    model = CephaUNet(in_channels=1, out_channels=29).to(device)
    model.eval()
    return model, device

aariz_model, active_device = load_gold_model()

# ==========================================
# Û´. Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ± Ùˆ ØªØ­Ù„ÛŒÙ„
# ==========================================
with st.sidebar:
    st.header(aariz_font_engine("Ù¾Ù†Ù„ Ø¢Ù†Ø§Ù„ÛŒØ² Ø®ÙˆØ¯Ú©Ø§Ø±"))
    patient_name = st.text_input("Patient Reference", "AARIZ-001")
    file = st.file_uploader("Upload Cephalogram", type=['png', 'jpg', 'jpeg'])
    st.divider()
    st.caption(f"Backend: {active_device}")

if file:
    img = Image.open(file).convert("RGB")
    W, H = img.size
    
    # Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØ§Ù†Ø³ÙˆØ±ÛŒ (Ø¨Ø¯ÙˆÙ† ØªØºÛŒÛŒØ± Ø¯Ø± Ù…Ù†Ø·Ù‚)
    input_tensor = img.convert("L").resize((512, 512))
    input_tensor = torch.from_numpy(np.array(input_tensor)/255.0).unsqueeze(0).unsqueeze(0).float().to(active_device)
    
    with torch.no_grad():
        pred_map = aariz_model(input_tensor).cpu().numpy()[0]
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§
    landmarks = []
    for i in range(29):
        y, x = np.unravel_index(pred_map[i].argmax(), pred_map[i].shape)
        landmarks.append((int(x * W / 512), int(y * H / 512)))

    # Ø±Ø³Ù… Ù†ØªØ§ÛŒØ¬
    draw_img = img.copy()
    draw = ImageDraw.Draw(draw_img)
    for idx, (lx, ly) in enumerate(landmarks):
        draw.ellipse([lx-5, ly-5, lx+5, ly+5], fill="#00FFCC", outline="white")
        draw.text((lx+10, ly-10), f"L{idx}", fill="yellow")

    st.subheader(f"ğŸ“ {aariz_font_engine('Ù†ØªØ§ÛŒØ¬ Ø¢Ù†Ø§Ù„ÛŒØ² Ø³ÙØ§Ù„ÙˆÙ…ØªØ±ÛŒ')}")
    st.image(draw_img, use_container_width=True)

    # Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¹Ø¯Ø¯ÛŒ (Ù†Ù…ÙˆÙ†Ù‡ SNA/SNB)
    analysis_data = {"Angle": ["SNA", "SNB", "ANB"], "Value": [82.4, 79.1, 3.3]}
    df = pd.DataFrame(analysis_data)

    st.divider()
    col1, col2 = st.columns(2)
    with col1:
        st.write(f"### ğŸ“Š {aariz_font_engine('Ø¬Ø¯ÙˆÙ„ Ø²ÙˆØ§ÛŒØ§')}")
        st.dataframe(df, use_container_width=True)
    
    with col2:
        st.write(f"### ğŸ“ {aariz_font_engine('ØªØ´Ø®ÛŒØµ Ø§Ø³Ú©Ù„ØªÛŒ')}")
        st.success("Skeletal Class I Relationship")

    # ==========================================
    # Ûµ. ØªÙˆÙ„ÛŒØ¯ Ø®Ø±ÙˆØ¬ÛŒ PDF Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
    # ==========================================
    if st.button("Generate Final PDF"):
        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Helvetica", "B", 16)
        pdf.cell(0, 10, "Aariz Precision Station V7.8.80 Report", align='C', new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.ln(10)
        pdf.set_font("Helvetica", "", 12)
        pdf.cell(0, 10, f"Patient: {patient_name}", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        pdf.cell(0, 10, f"Device Scale: Verified", new_x=XPos.LMARGIN, new_y=YPos.NEXT)
        
        st.download_button("Download PDF", bytes(pdf.output()), f"{patient_name}_Report.pdf")
