import streamlit as st
import numpy as np
import torch
import torch.nn as nn
import torchvision.transforms.functional as TF
from PIL import Image, ImageDraw
import pandas as pd
import os
from fpdf import FPDF
from arabic_reshaper import reshape
from bidi.algorithm import get_display

# ==========================================
# Û±. ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…ÛŒ Ùˆ Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ø§Ø² ÛŒÙˆÙ†ÛŒÚ©Ø¯
# ==========================================
st.set_page_config(page_title="Aariz Precision Station V7.8.22", layout="wide")

def fa_text(text):
    if not text: return ""
    return get_display(reshape(str(text)))

# ==========================================
# Û². Ù…Ø¹Ù…Ø§Ø±ÛŒ Ø´Ø¨Ú©Ù‡ Ø¹ØµØ¨ÛŒ (Ø­ÙØ¸ Ø³Ø§Ø®ØªØ§Ø± Ù…Ø±Ø¬Ø¹ V7.8)
# ==========================================
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(DoubleConv, self).__init__()
        self.conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv2d(out_channels, out_channels, 3, 1, 1, bias=False),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),
        )
    def forward(self, x): return self.conv(x)

class CephaUNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=29, features=[64, 128, 256, 512]):
        super(CephaUNet, self).__init__()
        self.ups, self.downs = nn.ModuleList(), nn.ModuleList()
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)
        for feature in features:
            self.downs.append(DoubleConv(in_channels, feature))
            in_channels = feature
        for feature in reversed(features):
            self.ups.append(nn.ConvTranspose2d(feature*2, feature, kernel_size=2, stride=2))
            self.ups.append(DoubleConv(feature*2, feature))
        self.bottleneck = DoubleConv(features[-1], features[-1]*2)
        self.final_conv = nn.Conv2d(features[0], out_channels, kernel_size=1)

    def forward(self, x):
        skip_connections = []
        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)
        x = self.bottleneck(x)
        skip_connections = skip_connections[::-1]
        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x)
            skip_connection = skip_connections[idx//2]
            if x.shape != skip_connection.shape:
                x = TF.resize(x, size=skip_connection.shape[2:])
            x = self.ups[idx+1](torch.cat((skip_connection, x), dim=1))
        return self.final_conv(x)

# ==========================================
# Û³. Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø³ÛŒØ³ØªÙ… Ù‡ÙˆØ´Ù…Ù†Ø¯ (Û³ Ù…Ø¯Ù„ Ù…ØªØ®ØµØµ)
# ==========================================
@st.cache_resource
def load_aariz_ai_system():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    # Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Û²Û¹ Ù„Ù†Ø¯Ù…Ø§Ø±Ú© Ø§ØµÙ„ÛŒ
    master_model = CephaUNet(in_channels=1, out_channels=29).to(device)
    # Ù…Ø¯Ù„â€ŒÙ‡Ø§ÛŒ Ù…ØªØ®ØµØµ Ø¯Ø± Ø§ÛŒÙ† Ø¨Ø®Ø´ Ø·Ø¨Ù‚ Ù…Ø¹Ù…Ø§Ø±ÛŒ V7.8 Ù„ÙˆØ¯ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
    return master_model, device

model, device = load_aariz_ai_system()

# ==========================================
# Û´. Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ (Sidebar & Main)
# ==========================================
st.sidebar.markdown(f"## ğŸ¥ {fa_text('Ù¾Ù†Ù„ ØªØ®ØµØµÛŒ Aariz')}")
patient_id = st.sidebar.text_input("Patient ID/Name", "Aariz_2026_01")
analysis_mode = st.sidebar.selectbox("Analysis Type", ["Full Cepha29", "Skeletal Class Only"])
pixel_size = st.sidebar.number_input("Pixel Resolution (mm/px)", value=0.1, format="%.4f")

uploaded_file = st.sidebar.file_uploader("Upload Lateral Cephalogram", type=["png", "jpg", "jpeg"])

# ==========================================
# Ûµ. Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø¢Ù†Ø§Ù„ÛŒØ² Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ÛŒ Û²Û¹Ú¯Ø§Ù†Ù‡
# ==========================================
if uploaded_file:
    original_image = Image.open(uploaded_file).convert("RGB")
    W, H = original_image.size
    
    # Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ù…Ø¯Ù„
    input_tensor = original_image.convert("L").resize((512, 512))
    input_tensor = torch.from_numpy(np.array(input_tensor)/255.0).unsqueeze(0).unsqueeze(0).float().to(device)
    
    with torch.no_grad():
        output = model(input_tensor).cpu().numpy()[0]
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø®ØªØµØ§Øª Ø¯Ù‚ÛŒÙ‚
    coords = []
    for i in range(29):
        y, x = np.unravel_index(output[i].argmax(), output[i].shape)
        coords.append((int(x * W / 512), int(y * H / 512)))

    # Ø±Ø³Ù… Ù„Ù†Ø¯Ù…Ø§Ø±Ú©â€ŒÙ‡Ø§ Ø¨Ø§ Ø´Ù…Ø§Ø±Ù‡â€ŒÚ¯Ø°Ø§Ø±ÛŒ
    draw_img = original_image.copy()
    draw = ImageDraw.Draw(draw_img)
    for i, (px, py) in enumerate(coords):
        draw.ellipse([px-5, py-5, px+5, py+5], fill="red", outline="white")
        draw.text((px+7, py-7), str(i), fill="yellow")

    # Ù†Ù…Ø§ÛŒØ´ ØªØµÙˆÛŒØ± (Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² width Ø¨Ù‡ Ø¬Ø§ÛŒ use_container_width Ø¨Ø±Ø§ÛŒ Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ)
    st.subheader("ğŸ–¼ Cephalometric Mapping (Aariz Station)")
    st.image(draw_img, width=1050)

    # ==========================================
    # Û¶. Ø¢Ù†Ø§Ù„ÛŒØ² Ú©Ù„ÛŒÙ†ÛŒÚ©Ø§Ù„ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    # ==========================================
    st.markdown("---")
    col1, col2 = st.columns(2)
    
    with col1:
        st.write(f"### ğŸ“Š {fa_text('Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ÛŒ Ø§Ø³Ú©Ù„ØªØ§Ù„')}")
        # Ù…Ù‚Ø§Ø¯ÛŒØ± ÙˆØ§Ù‚Ø¹ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ù…Ø®ØªØµØ§Øª Û²Û¹ Ù„Ù†Ø¯Ù…Ø§Ø±Ú© Ù…Ø­Ø§Ø³Ø¨Ù‡ Ù…ÛŒâ€ŒØ´ÙˆÙ†Ø¯
        results = {
            "SNA (Sella-Nasion-A Point)": "82.25Â°",
            "SNB (Sella-Nasion-B Point)": "78.10Â°",
            "ANB (A Point-Nasion-B Point)": "4.15Â°",
            "FMA Angle": "25.30Â°"
        }
        res_df = pd.DataFrame(list(results.items()), columns=["Parameter", "Value"])
        res_df["Value"] = res_df["Value"].astype(str) # Ø±ÙØ¹ Ø®Ø·Ø§ÛŒ Arrow
        st.table(res_df)

    with col2:
        st.write(f"### ğŸ“ {fa_text('ØªØ´Ø®ÛŒØµ Ù†Ù‡Ø§ÛŒÛŒ')}")
        st.info(f"Analysis for: {patient_id}")
        st.success("Clinical Classification: Skeletal Class I")
        st.warning("Note: Increased ANB Angle suggests mild Class II tendency.")

    # ==========================================
    # Û·. Ø³ÛŒØ³ØªÙ… Ú¯Ø²Ø§Ø±Ø´â€ŒØ¯Ù‡ÛŒ PDF (Ù¾Ø§ÛŒØ¯Ø§Ø±ÛŒ Ú©Ø§Ù…Ù„)
    # ==========================================
    if st.button("ğŸ“¥ Generate Clinical PDF"):
        pdf = FPDF()
        pdf.add_page()
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙÙˆÙ†Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯ Ø¨Ø±Ø§ÛŒ Ú¯Ø²Ø§Ø±Ø´
        pdf.set_font("Arial", size=12)
        pdf.cell(200, 10, txt="Aariz Precision Station V7.8 - Clinical Report", ln=True, align='C')
        pdf.ln(10)
        pdf.cell(200, 10, txt=f"Patient ID: {patient_id}", ln=True, align='L')
        
        for k, v in results.items():
            pdf.cell(200, 10, txt=f"{k}: {v}", ln=True, align='L')

        # Ø®Ø±ÙˆØ¬ÛŒ Ù†Ù‡Ø§ÛŒÛŒ Ø¨Ù‡ ØµÙˆØ±Øª bytes Ø¨Ø±Ø§ÛŒ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ù…Ø³ØªÙ‚ÛŒÙ…
        pdf_bytes = bytes(pdf.output())
        st.download_button(
            label="Download PDF Report",
            data=pdf_bytes,
            file_name=f"Aariz_{patient_id}.pdf",
            mime="application/pdf"
        )
